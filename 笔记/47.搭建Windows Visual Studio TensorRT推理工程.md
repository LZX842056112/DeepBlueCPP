## 搭建Windows Visual Studio TensorRT推理工程



下面按「从零建 VS 工程」的方式一步步来说明，假设环境是：

- Windows 10/11  
- Visual Studio 2019 或 2022（C++ 桌面开发组件已安装）  
- 已安装 CUDA（例如 11.x/12.x）  
- 已安装 TensorRT 8.x（解压版）  
- 已安装 OpenCV for Windows

---

## 0. 准备工作（环境变量）

建议先在系统里设几个环境变量，方便在 VS 里引用：

1. CUDA 安装好后，通常会自动有：  
   `CUDA_PATH = C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.2`  
   （以你实际安装版本为准）

2. TensorRT（假设你解压到）：  
   `C:\TensorRT-8.6.1.6`  
   自己新建一个系统环境变量：  
   - 变量名：`TENSORRT_DIR`  
   - 值：`C:\TensorRT-8.6.1.6`

3. OpenCV（假设你解压到）：  
   `C:\opencv\build`  
   自己新建一个系统环境变量：  
   - 变量名：`OPENCV_DIR`  
   - 值：`C:\opencv\build`

> **以上路径只是示例，你要用你机器上的真实路径**

---

## 1. 创建 Visual Studio 控制台工程

1. 打开 Visual Studio  
2. “创建新项目” → 选择  
   - **C++** → “控制台应用程序” / “Console App”  
3. 项目名称：例如 `MnistTensorRT`  
4. 位置随便（不要有中文和空格最好）  
5. 勾选 “使用 CMake” 的不要选，正常 MSBuild 工程即可  
6. 完成后，VS 会生成一个 `.cpp` 模板文件（`xxx.cpp`）

将我之前给你的 TensorRT 推理代码整体替换到这个 `.cpp` 里即可（或新建一个 `.cpp` 文件，把样例代码复制进去）。

---

## 2. 选择平台和配置

1. VS 顶部工具栏：  
   - “解决方案配置” 选 **Release**  
   - “解决方案平台” 选 **x64**

> **不要用 Win32，也不要用 Debug（TensorRT 官方预编译库通常只提供 Release）**。

---

## 3. 配置项目属性（包含目录 / 库目录 / 依赖库）

右键项目 → “属性”（Properties），确保左上角：

- “配置(Configuration)”：可以选 **Release** 或 **所有配置(All Configurations)**  
- “平台(Platform)”：选 **x64** 或 “所有平台”

### 3.1 C/C++：包含目录 & 语言标准

在 **C/C++ → 常规(General) → 附加包含目录(Additional Include Directories)** 中加入：

```text
$(TENSORRT_DIR)\include
$(CUDA_PATH)\include
$(OPENCV_DIR)\include          // 新版 OpenCV 也可能是 $(OPENCV_DIR)\build\include
```

> 具体看你 OpenCV 解压后的目录结构，一般 prebuilt 是 `..\build\include`。

在 **C/C++ → 语言(Language) → C++ 语言标准(C++ Language Standard)** 里选择：

```text
ISO C++17 Standard (/std:c++17)
```

在 **C/C++ → 代码生成(Code Generation) → 运行库(Runtime Library)** 里选择（针对 Release）：

```text
多线程 DLL (/MD)
```

> **TensorRT / CUDA / OpenCV 预编译库一般都是 /MD，避免 /MT 造成运行时冲突**。

### 3.2 链接器：库目录

在 **链接器(Linker) → 常规(General) → 附加库目录(Additional Library Directories)** 中加入：

```text
$(TENSORRT_DIR)\lib
$(CUDA_PATH)\lib\x64
$(OPENCV_DIR)\x64\vc16\lib
```

说明：

- `$(TENSORRT_DIR)\lib`：TensorRT 的 `.lib` 和 `.dll` 所在目录  
- `$(CUDA_PATH)\lib\x64`：CUDA 的 `.lib`  
- `$(OPENCV_DIR)\x64\vc16\lib`：OpenCV 对应 VS2019 的库目录  
  - 如果是 VS2022 的预编译 OpenCV，目录可能是 `vc17`，请根据实际情况修改。

### 3.3 链接器：附加依赖项

在 **链接器(Linker) → 输入(Input) → 附加依赖项(Additional Dependencies)** 中添加（在原有的基础上追加）：

```text
nvinfer.lib
nvonnxparser.lib
nvonnxparser_runtime.lib       // 有的版本需要
cudart.lib
opencv_world480.lib            // 这里版本号换成你真实的，如 opencv_world470.lib
```

注意事项：

1. TensorRT 库文件名大致如下（在 `$(TENSORRT_DIR)\lib` 下能看到）：
   - `nvinfer.lib`
   - `nvinfer_plugin.lib`（如果你的模型用到 TensorRT 插件，可以一并加上）
   - `nvonnxparser.lib`
   - `nvonnxparser_runtime.lib`
2. CUDA：
   - 我们只用了 CUDA runtime API（`cudaMalloc/cudaMemcpy`），链接 `cudart.lib` 即可。
3. OpenCV：
   - 预编译版通常有一个 “一体化” 的 `opencv_worldxxx.lib`。  
   - 如果你的 OpenCV 是拆分多个模块（`opencv_corexxx.lib`、`opencv_imgprocxxx.lib` 等），
     就把这些你需要的模块都加进去。  
   - 名字一定要和你 `lib` 目录里的文件名一一对应。

> 如果编译时出现 `unresolved external symbol cudaMalloc` / `cudaMemcpy`，基本就是 `cudart.lib` 没链接到；  
> 出现 `nvinfer` 相关 unresolved external，就是 TensorRT 的 `.lib` 没配好。

---

## 4. 复制运行时 DLL 或配置 PATH

编译通过之后，运行时如果报错 `找不到 nvinfer.dll`、`opencv_world480.dll` 等，就是动态库找不到。

有两种解决方式（任选其一或混合）：

### 方式 A：把 DLL 复制到 exe 同目录

假设你的可执行文件在：

```text
$(SolutionDir)x64\Release\
```

需要拷贝的 DLL 一般包括：

- 从 `$(TENSORRT_DIR)\lib\` 拷：
  - `nvinfer.dll`
  - `nvonnxparser.dll`
  - `nvonnxparser_runtime.dll`
  - （如有）`nvinfer_plugin.dll` 等
- 从 `$(CUDA_PATH)\bin\` 拷：
  - `cudart64_*.dll`（如 `cudart64_120.dll`，具体版本视 CUDA 而定）
- 从 `$(OPENCV_DIR)\x64\vc16\bin\` 拷：
  - `opencv_world480.dll`（或对应版本）

你可以手动复制，也可以在 **项目属性 → 生成事件 → 生成后事件(Post-Build Event)** 里写简单批处理，例如：

```bat
xcopy /Y /D "$(TENSORRT_DIR)\lib\*.dll" "$(OutDir)"
xcopy /Y /D "$(CUDA_PATH)\bin\cudart64*.dll" "$(OutDir)"
xcopy /Y /D "$(OPENCV_DIR)\x64\vc16\bin\opencv_world480.dll" "$(OutDir)"
```

（注意修改版本号）

### 方式 B：把这些目录加入系统 PATH

把下面这些目录加到系统环境变量 `PATH` 中：

```text
$(TENSORRT_DIR)\lib
$(CUDA_PATH)\bin
$(OPENCV_DIR)\x64\vc16\bin
```

然后重启 VS，让它继承新的 PATH。这样运行 exe 时就能在 PATH 里找到 DLL。

---

## 5. 模型和图片路径

```cpp
std::string model_path = "../../mnist_cnn.onnx";
std::string image_path = "../../test_digit.png";
```

VS 默认工作目录通常是工程目录（`$(ProjectDir)`）。`"../../"` 会根据你的工程目录不同而定位到不一样的位置。

建议：

- 把 `mnist_cnn.onnx` 和 `test_digit.png` 放到项目目录或 `$(ProjectDir)\data\` 之类的文件夹
- 代码里写成类似：

```cpp
std::string model_path = "..\\..\\mnist_cnn.onnx";   // 或者
std::string model_path = "mnist_cnn.onnx";          // 直接放在可执行文件同目录
```

或者利用宏（自己定义）：

```cpp
#define PROJECT_DIR "C:\\path\\to\\your\\project\\"
std::string model_path = std::string(PROJECT_DIR) + "mnist_cnn.onnx";
```

只要保证运行时能找到这两个文件即可。

---

## 6. 编译与运行

1. 确保：
   - 配置：**Release**
   - 平台：**x64**
2. 菜单栏 → “生成(Build)” → “生成解决方案(Build Solution)”  
3. 如果编译/链接出错，按以下顺序检查：
   - C/C++ 头文件是否能正确找到（`NvInfer.h`、`NvOnnxParser.h`、`cuda_runtime_api.h`、`opencv2/opencv.hpp`）
   - 链接器的库目录和库名是否和你本地 `lib` 文件一一对应
4. 编译成功后，按 F5 或直接运行 exe
