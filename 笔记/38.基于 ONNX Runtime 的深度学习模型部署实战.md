# 课程项目：基于 ONNX Runtime 的深度学习模型部署实战

**项目目标：** 训练一个手写数字识别模型 (MNIST)，并将其部署到 Python 和 C++ 环境中。

## 第一部分：模型训练与导出

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
import torch.onnx
import os
import time

EPOCHS = 10
BATCH_SIZE = 64
TEST_BATCH_SIZE = 1000
LEARNING_RATE = 0.01
DEVICE = torch.device("cpu")

class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
        self.relu = nn.ReLU()
        self.pool = nn.MaxPool2d(kernel_size=2)
        self.fc = nn.Linear(10 * 12 * 12, 10)

    def forward(self, x):
        x = self.pool(self.relu(self.conv1(x)))
        x = x.view(-1, 10 * 12 * 12)
        x = self.fc(x)
        return x

def train(model, train_loader, optimizer, criterion, epoch):
    model.train()
    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(DEVICE), target.to(DEVICE)
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()

        if batch_idx % 100 == 0:
            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '
                  f'({100. * batch_idx / len(train_loader):.0f}%)]\tLoss: {loss.item():.6f}')

def test(model, test_loader, criterion):
    model.eval()
    test_loss = 0
    correct = 0
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(DEVICE), target.to(DEVICE)
            output = model(data)
            test_loss += criterion(output, target).item()
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()

    test_loss /= len(test_loader)
    accuracy = 100. * correct / len(test_loader.dataset)
    
    print(f'\nTest set: Average loss: {test_loss:.4f}, '
          f'Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.2f}%)\n')
    return accuracy

def main():
    print(f"开始训练任务，使用设备: {DEVICE}")
    
    # mean=0.1307, std=0.3081
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))
    ])

    train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)
    test_dataset = datasets.MNIST('./data', train=False, transform=transform)

    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, shuffle=False)

    model = SimpleCNN().to(DEVICE)
    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.5)
    criterion = nn.CrossEntropyLoss()

    best_accuracy = 0.0
    
    start_time = time.time()
    
    for epoch in range(1, EPOCHS + 1):
        train(model, train_loader, optimizer, criterion, epoch)
        current_accuracy = test(model, test_loader, criterion)
        
        if current_accuracy > best_accuracy:
            best_accuracy = current_accuracy
            torch.save(model.state_dict(), "mnist_cnn_best.pth")
            print(f"发现新高准确率 ({best_accuracy:.2f}%)，模型权重已保存。")
    
    print(f"训练结束，耗时: {time.time() - start_time:.1f}秒")
    print(f"最佳准确率: {best_accuracy:.2f}%")

    print("-" * 30)
    print("正在导出最佳模型到 ONNX...")
    
    model.load_state_dict(torch.load("mnist_cnn_best.pth"))
    model.eval()
    model.to('cpu') # 导出过程建议在 CPU 上进行，通用性更好

    dummy_input = torch.randn(1, 1, 28, 28)
    output_onnx_name = "mnist_cnn.onnx"
    
    torch.onnx.export(model, 
                      dummy_input, 
                      output_onnx_name, 
                      input_names=['input'], 
                      output_names=['output'])
    
    print(f"ONNX 模型已生成: {output_onnx_name}")

if __name__ == '__main__':
    main()
```

-----

## 第二部分：准备测试图片

```python
import cv2
import numpy as np

img = np.zeros((28, 28), dtype=np.uint8)

cv2.putText(img, "5", (4, 22), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255), 2)

cv2.imwrite("test_digit.png", img)
print("测试图片 test_digit.png (数字5) 已生成")
```

-----

## 第三部分：Python 版本推理 (Python Inference)

```python
import onnxruntime as ort
import numpy as np
import cv2

def preprocess(image_path):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if img is None:
        raise Exception("无法读取图片，请检查路径")

    img = cv2.resize(img, (28, 28))

    img = img.astype(np.float32) / 255.0
    
    # mean=0.1307, std=0.3081
    img = (img - 0.1307) / 0.3081

    # 5. 增加维度 (H, W) -> (1, 1, H, W), 要想明白
    img = np.expand_dims(img, axis=0)
    img = np.expand_dims(img, axis=0)
    
    return img

def main():
    onnx_model_path = "mnist_cnn.onnx"
    image_path = "test_digit.png"

    try:
        session = ort.InferenceSession(onnx_model_path, providers=['CPUExecutionProvider'])
    except Exception as e:
        print(f"错误: 无法加载模型。请确保已运行 1_train_export.py。详情: {e}")
        return

    input_tensor = preprocess(image_path)
    
    input_name = session.get_inputs()[0].name  # 'input'
    output_name = session.get_outputs()[0].name # 'output'

    outputs = session.run([output_name], {input_name: input_tensor})
    
    logits = outputs[0] # 原始输出
    probabilities = np.exp(logits) / np.sum(np.exp(logits)) # Softmax (可选，看概率)
    prediction = np.argmax(logits)
    
    print(f"置信度: {probabilities[0][prediction]:.4f}")


if __name__ == "__main__":
    main()
```

-----

## ⚙️ 第四部分：C++ 版本推理 (C++ Inference)

### 1\. 环境准备

```cmake
cmake_minimum_required(VERSION 3.10)
project(MnistCpp)

set(CMAKE_CXX_STANDARD 17)

find_package(OpenCV REQUIRED)

find_path(ONNXRUNTIME_INCLUDE_DIR 
    NAMES onnxruntime_cxx_api.h
    PATHS /usr/local/include /usr/include
    PATH_SUFFIXES onnxruntime core/session
)

find_library(ONNXRUNTIME_LIB 
    NAMES onnxruntime
    PATHS /usr/local/lib /usr/lib
)

if(NOT ONNXRUNTIME_INCLUDE_DIR OR NOT ONNXRUNTIME_LIB)
    message(FATAL_ERROR "未找到 ONNX Runtime！请确认已安装到 /usr/local 或设置相关路径。")
else()
    message(STATUS "Found ONNX Runtime Include: ${ONNXRUNTIME_INCLUDE_DIR}")
    message(STATUS "Found ONNX Runtime Lib: ${ONNXRUNTIME_LIB}")
endif()

add_executable(mnist_demo main.cpp)

target_include_directories(mnist_demo PRIVATE ${ONNXRUNTIME_INCLUDE_DIR})
target_link_libraries(mnist_demo ${OpenCV_LIBS} ${ONNXRUNTIME_LIB})
```

### 3\. C++ 核心代码

```cpp
#include <iostream>
#include <vector>
#include <numeric>
#include <opencv2/opencv.hpp>
#include <onnxruntime_cxx_api.h>

std::vector<float> preprocess(const cv::Mat& img) {
    cv::Mat processed;
    
    cv::resize(img, processed, cv::Size(28, 28));
    
    processed.convertTo(processed, CV_32F, 1.0 / 255.0);

    // 3. 标准化 (Mean=0.1307, Std=0.3081)
    processed = (processed - 0.1307) / 0.3081;

    // 4. Flatten (展开为一维向量)
    // OpenCV Mat 是行优先存储，可以直接拷贝
    std::vector<float> input_tensor_values;
    if (processed.isContinuous()) {
        input_tensor_values.assign((float*)processed.datastart, (float*)processed.dataend);
    } else {
        for (int i = 0; i < processed.rows; ++i)
            input_tensor_values.insert(input_tensor_values.end(), processed.ptr<float>(i), processed.ptr<float>(i) + processed.cols);
    }
    return input_tensor_values;
}

int main() {
    std::string model_path = "../../mnist_cnn.onnx"; 
    std::string image_path = "../../test_digit.png";

    Ort::Env env(ORT_LOGGING_LEVEL_WARNING, "MnistCpp");
    Ort::SessionOptions session_options;
    Ort::Session session(env, model_path.c_str(), session_options);

    cv::Mat img = cv::imread(image_path, cv::IMREAD_GRAYSCALE);
    if (img.empty()) {
        std::cerr << "Error: Could not read image from " << image_path << std::endl;
        return -1;
    }

    std::vector<float> input_tensor_values = preprocess(img);
    
    std::vector<int64_t> input_shape = {1, 1, 28, 28};
    size_t input_tensor_size = 28 * 28;

    auto memory_info = Ort::MemoryInfo::CreateCpu(OrtArenaAllocator, OrtMemTypeDefault);
    
    Ort::Value input_tensor = Ort::Value::CreateTensor<float>(
        memory_info, 
        input_tensor_values.data(), 
        input_tensor_size, 
        input_shape.data(), 
        input_shape.size()
    );

    const char* input_names[] = {"input"};
    const char* output_names[] = {"output"};

    std::cout << "Running Inference..." << std::endl;
    auto output_tensors = session.Run(
        Ort::RunOptions{nullptr}, 
        input_names, 
        &input_tensor, 
        1, 
        output_names, 
        1
    );

    float* floatarr = output_tensors[0].GetTensorMutableData<float>();
    
    auto max_it = std::max_element(floatarr, floatarr + 10);
    int prediction = std::distance(floatarr, max_it);
    float confidence = *max_it;

    std::cout << "-----------------------" << std::endl;
    std::cout << "Prediction Result: " << prediction << std::endl;
    std::cout << "Raw Logit Value:   " << confidence << std::endl;
    std::cout << "-----------------------" << std::endl;

    return 0;
}
```

### 4\. 编译与运行

```bash
mkdir build
cd build
cmake ..
make
./mnist_demo
```
